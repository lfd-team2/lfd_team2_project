{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from eda.column_type_dicts import dtype_dict_train\n",
    "from eda.column_type_dicts import dtype_dict_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 EDA\n",
    "## 1.1 Data Description and Data Types\n",
    "\n",
    "From the feature description, we know that there are 7 histogram variables, corresponding to 70 features. From checking the column names manually, we have found that colums with these names:\n",
    "* ag_000 to ag_009\n",
    "* ay_000 to ay_008\n",
    "* az_000 to az_009\n",
    "* ba_000 to ba_009\n",
    "* cn_000 to ba_009\n",
    "* cn_000 to cn_009\n",
    "* cs_000 to cs_009\n",
    "* ee_000 to ee_009\n",
    "\n",
    "are indeed histogram variables. Those are different from the rest of the data, which are just counters. While reading the data, We will keep this in mind and seperate these two types of features.\n",
    "\n",
    "Also, from the kaggle challenge website, we have found out that most of the variables have 'na' values, which means NULL, we need to handle this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file using pandas\n",
    "dataframe_train = pd.read_csv('data/aps_failure_training_set.csv', dtype=dtype_dict_test, na_values='na', low_memory=False)\n",
    "\n",
    "# sort the columns by number of missing values and save them\n",
    "null_counts = dataframe_train.isnull().sum().sort_values(ascending=0).to_dict()\n",
    "with open('eda/missing_values_train.txt', 'w') as f:\n",
    "    f.write('Number of missing values per column:\\n')\n",
    "    for key, value in null_counts.items():\n",
    "        f.write('{}: {:.3f}\\n'.format(key, value/len(dataframe_train)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result of counting nulls in the columns, the null counts are very severe in the given columns:\n",
    "| column | null% | column | null% | column | null% | column | null% | column | null% | column | null% | column | null% |\n",
    "| ------ | ----- | ------ | ----- | ------ | ----- | ------ | ----- | ------ | ----- | ------ | ----- | ------ | ----- |\n",
    "| br_000 | 0.821 | bq_000 | 0.812 | bp_000 | 0.796 | bo_000 | 0.772 | cr_000 | 0.772 | ab_000 | 0.772 | bn_000 | 0.733 |\n",
    "| bm_000 | 0.659 | bl_000 | 0.455 | bk_000 | 0.384 | cf_000 | 0.248 | cg_000 | 0.248 | ch_000 | 0.248 | co_000 | 0.248 |\n",
    "| ad_000 | 0.248 | cv_000 | 0.230 | da_000 | 0.230 | cz_000 | 0.230 | cy_000 | 0.230 | cx_000 | 0.230 | db_000 | 0.230 |\n",
    "| cu_000 | 0.230 | ct_000 | 0.230 | dc_000 | 0.230 | ec_00  | 0.171 | cm_000 | 0.165 | cl_000 | 0.159 | ed_000 | 0.159 |\n",
    "\n",
    "We can drop these columns since they are mostly null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzscore is\u001b[39m\u001b[38;5;124m\"\u001b[39m, zscore)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m zscore\n\u001b[1;32m---> 17\u001b[0m zscore(\u001b[43mtrain_data\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# z-score normalization\n",
    "\n",
    "# standard deviation formula\n",
    "def zscore(values):\n",
    "    avg = sum(values)/len(values)\n",
    "    print(avg)\n",
    "    mean = sum(values)/len(values)\n",
    "    print(\"mean is\", mean)\n",
    "    variance = sum([(i-mean)**2 for i in values])/len(values)\n",
    "    print(\"variance is\", variance)\n",
    "    std = variance**0.5\n",
    "    print(\"standard deviation is\", std)\n",
    "    zscore = [(i-mean)/std for i in values]\n",
    "    print(\"zscore is\", zscore)\n",
    "    return zscore\n",
    "\n",
    "zscore(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
