{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLG 454E Term Project\n",
    "\n",
    "## Team 2\n",
    "\n",
    "### Fatih Baskın\n",
    "#### 150210710\n",
    "\n",
    "### Bilgenur Çelik\n",
    "#### 150200063"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Exploratory Data Analysis\n",
    "\n",
    "## 1.1 Data Description and Data Types\n",
    "\n",
    "From the feature description, we know that there are 7 histogram variables, corresponding to 70 features. From checking the column names manually, we have found that colums with these names:\n",
    "* ag_000 to ag_009\n",
    "* ay_000 to ay_008\n",
    "* az_000 to az_009\n",
    "* ba_000 to ba_009\n",
    "* cn_000 to ba_009\n",
    "* cn_000 to cn_009\n",
    "* cs_000 to cs_009\n",
    "* ee_000 to ee_009\n",
    "\n",
    "are indeed histogram variables. Those are different from the rest of the data, which are just counters.\n",
    "\n",
    "Also, from the kaggle challenge website, we have found out that most of the variables have 'na' values, which means NULL, we need to handle this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 172)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>76698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>33058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>41040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.280000e+02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>neg</td>\n",
       "      <td>60874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id class  aa_000  ab_000        ac_000  ad_000  ae_000  af_000  ag_000  \\\n",
       "0   1   neg   76698     NaN  2.130706e+09   280.0     0.0     0.0     0.0   \n",
       "1   2   neg   33058     NaN  0.000000e+00     NaN     0.0     0.0     0.0   \n",
       "2   3   neg   41040     NaN  2.280000e+02   100.0     0.0     0.0     0.0   \n",
       "3   4   neg      12     0.0  7.000000e+01    66.0     0.0    10.0     0.0   \n",
       "4   5   neg   60874     NaN  1.368000e+03   458.0     0.0     0.0     0.0   \n",
       "\n",
       "   ag_001  ...     ee_002    ee_003    ee_004    ee_005    ee_006    ee_007  \\\n",
       "0     0.0  ...  1240520.0  493384.0  721044.0  469792.0  339156.0  157956.0   \n",
       "1     0.0  ...   421400.0  178064.0  293306.0  245416.0  133654.0   81140.0   \n",
       "2     0.0  ...   277378.0  159812.0  423992.0  409564.0  320746.0  158022.0   \n",
       "3     0.0  ...      240.0      46.0      58.0      44.0      10.0       0.0   \n",
       "4     0.0  ...   622012.0  229790.0  405298.0  347188.0  286954.0  311560.0   \n",
       "\n",
       "     ee_008  ee_009  ef_000  eg_000  \n",
       "0   73224.0     0.0     0.0     0.0  \n",
       "1   97576.0  1500.0     0.0     0.0  \n",
       "2   95128.0   514.0     0.0     0.0  \n",
       "3       0.0     0.0     4.0    32.0  \n",
       "4  433954.0  1218.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "training_data_frame = pd.read_csv('data/aps_failure_training_set.csv', na_values='na')\n",
    "print(training_data_frame.shape)\n",
    "training_data_frame.head()\n",
    "\n",
    "testing_data_frame = pd.read_csv('data/aps_failure_test_set.csv', na_values='na')\n",
    "print(testing_data_frame.shape)\n",
    "testing_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtype_dict_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# read csv file using pandas\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataframe_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/aps_failure_training_set.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mdtype_dict_test\u001b[49m, na_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mna\u001b[39m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# sort the columns by number of missing values and save them\u001b[39;00m\n\u001b[0;32m      5\u001b[0m null_counts \u001b[38;5;241m=\u001b[39m dataframe_train\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dtype_dict_test' is not defined"
     ]
    }
   ],
   "source": [
    "# read csv file using pandas\n",
    "dataframe_train = pd.read_csv('data/aps_failure_training_set.csv', dtype=dtype_dict_test, na_values='na', low_memory=False)\n",
    "\n",
    "# sort the columns by number of missing values and save them\n",
    "null_counts = dataframe_train.isnull().sum().sort_values(ascending=0).to_dict()\n",
    "with open('eda/missing_values_train.txt', 'w') as f:\n",
    "    f.write('Number of missing values per column:\\n')\n",
    "    for key, value in null_counts.items():\n",
    "        f.write('{}: {:.3f}\\n'.format(key, value/len(dataframe_train)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result of counting nulls in the columns, the null counts are very severe in the given columns:\n",
    "| column | null% | column | null% | column | null% | column | null% | column | null% | column | null% | column | null% |\n",
    "| ------ | ----- | ------ | ----- | ------ | ----- | ------ | ----- | ------ | ----- | ------ | ----- | ------ | ----- |\n",
    "| br_000 | 0.821 | bq_000 | 0.812 | bp_000 | 0.796 | bo_000 | 0.772 | cr_000 | 0.772 | ab_000 | 0.772 | bn_000 | 0.733 |\n",
    "| bm_000 | 0.659 | bl_000 | 0.455 | bk_000 | 0.384 | cf_000 | 0.248 | cg_000 | 0.248 | ch_000 | 0.248 | co_000 | 0.248 |\n",
    "| ad_000 | 0.248 | cv_000 | 0.230 | da_000 | 0.230 | cz_000 | 0.230 | cy_000 | 0.230 | cx_000 | 0.230 | db_000 | 0.230 |\n",
    "| cu_000 | 0.230 | ct_000 | 0.230 | dc_000 | 0.230 | ec_00  | 0.171 | cm_000 | 0.165 | cl_000 | 0.159 | ed_000 | 0.159 |\n",
    "\n",
    "We can drop these columns since they are mostly null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzscore is\u001b[39m\u001b[38;5;124m\"\u001b[39m, zscore)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m zscore\n\u001b[1;32m---> 17\u001b[0m zscore(\u001b[43mtrain_data\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# z-score normalization\n",
    "\n",
    "# standard deviation formula\n",
    "def zscore(values):\n",
    "    avg = sum(values)/len(values)\n",
    "    print(avg)\n",
    "    mean = sum(values)/len(values)\n",
    "    print(\"mean is\", mean)\n",
    "    variance = sum([(i-mean)**2 for i in values])/len(values)\n",
    "    print(\"variance is\", variance)\n",
    "    std = variance**0.5\n",
    "    print(\"standard deviation is\", std)\n",
    "    zscore = [(i-mean)/std for i in values]\n",
    "    print(\"zscore is\", zscore)\n",
    "    return zscore\n",
    "\n",
    "zscore(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
